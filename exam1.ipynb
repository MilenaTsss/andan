{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NayH_1nXx5dH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "# from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.regression.linear_model import OLSResults\n",
        "from math import sqrt\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "sns.set(style=\"darkgrid\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data frames\n",
        "df_train_1 = pd.read_csv('TrainData.csv')\n",
        "df_test_1 = pd.read_csv('TestData.csv')\n",
        "print(df_train_1.head())\n",
        "print(df_test_1.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOk2_SynzNVC",
        "outputId": "fc637747-850d-43f8-d7e2-9d4dcb61cb8e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0      1      2  3   4  5       6  7  8   9  10  11   12      13     target\n",
            "0  1  34.75  15.00  2  12  7   5.375  A  1   9   1   2    0   135.0      Churn\n",
            "1  1  19.17   4.00  1   3  4   1.000  B  0   0   1   2  360  1001.0  Not churn\n",
            "2  1  20.25   9.96  2  10  2   0.000  A  0   0   0   2    0     1.0      Churn\n",
            "3  1    NaN  28.00  1   8  4  28.500  A  1  40   0   2    0    16.0      Churn\n",
            "4  1  22.58   1.50  1   6  4   0.540  B  0   0   1   2  120    68.0  Not churn\n",
            "   0      1       2  3   4  5      6  7  8  9  10  11   12   13\n",
            "0  1  32.08   4.000  1  13  4  1.500  B  0  0   1   2  120    1\n",
            "1  0  23.50   1.500  2   9  4  0.875  B  0  0   1   2  160    1\n",
            "2  0  33.25   2.500  1   8  4  2.500  B  0  0   1   2    0    3\n",
            "3  1  74.83  19.000  1   1  1  0.040  B  1  2   0   2    0  352\n",
            "4  1  20.17   5.625  2   9  4  1.710  A  0  0   0   1  120    1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 1 (0.15 балла). Проверьте, есть ли в тренировочных и в тестовых данных пропуски? Укажите количество столбцов тренировочной выборки, имеющих пропуски"
      ],
      "metadata": {
        "id": "Z1VHjrOQOEA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_missing = df_train_1.isnull().sum() # get missing in train\n",
        "test_missing = df_test_1.isnull().sum() # get missing in test\n",
        "\n",
        "num_train_columns_with_missing = (train_missing > 0).sum() # count num of columns with missing data\n",
        "print(num_train_columns_with_missing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWVHT0hwyamA",
        "outputId": "b9854593-e9e9-4f4d-97ae-40f34fab4e47"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_2 = pd.read_csv('train.csv')\n",
        "df_test_2 = pd.read_csv('test.csv')\n",
        "print(df_train_2.head())\n",
        "print(df_test_2.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ID2MRy0C0H3B",
        "outputId": "4fc7a506-a593-41e4-8f4e-a91f82f25a2d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
            "0           1057     1          2.7         0   3       1          41    0.1   \n",
            "1           1619     1          1.9         0   2       1          21    0.4   \n",
            "2           1028     1          2.8         0   1       1          30    0.1   \n",
            "3           1994     1          0.8         1   2       1           7    0.6   \n",
            "4           1603     1          0.5         1   1       1          17    0.5   \n",
            "\n",
            "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
            "0         97        4  ...        397       891  2033    16     9          2   \n",
            "1        138        1  ...         46       562  1641     7     2         13   \n",
            "2        193        1  ...       1801      1923  1424    18     4         13   \n",
            "3         88        8  ...        667       711   454    11     8          6   \n",
            "4        114        2  ...        430      1207  1637    17     3         11   \n",
            "\n",
            "   three_g  touch_screen wifi  price_range  \n",
            "0        1           Yes    0            1  \n",
            "1        1            No    0            1  \n",
            "2        1            No    1            1  \n",
            "3        1           Yes    0            0  \n",
            "4        1            No    1            1  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
            "0           1379     0          0.5         1   1       0          19    0.3   \n",
            "1            587     1          2.5         0  16       1          51    0.6   \n",
            "2           1866     0          1.4         0   0       0          30    0.5   \n",
            "3           1242     0          1.1         1   0       0          10    0.6   \n",
            "4            726     0          2.9         0   0       0          43    0.1   \n",
            "\n",
            "   mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
            "0        134        8  17        387       671  3912    11     2         19   \n",
            "1        111        1  17        244      1361  2746    10     4          7   \n",
            "2        182        3   0        108      1781  3834    16    11          8   \n",
            "3        165        2   1        459      1225  1050    11     1          4   \n",
            "4        101        8   0        666       760  1446    17     2          8   \n",
            "\n",
            "   three_g touch_screen  wifi  \n",
            "0        0          Yes     1  \n",
            "1        1           No     1  \n",
            "2        0           No     0  \n",
            "3        1           No     1  \n",
            "4        1          Yes     0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 1 (0.25 балла).\n",
        "\n",
        "В скольких столбцах таблицы среднее значение измеряется в сотнях? (не в десятках и не в тысячах)."
      ],
      "metadata": {
        "id": "vMq9NDwvOKkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Отфильтровывание только числовых столбцов в выборке\n",
        "df_train_numeric = df_train_2.select_dtypes(include=['number'])\n",
        "df_test_numeric = df_test_2.select_dtypes(include=['number'])\n",
        "\n",
        "# Вычисление среднего значения для каждого числового столбца в выборке\n",
        "train_mean_values = df_train_numeric.mean()\n",
        "test_mean_values = df_test_numeric.mean()\n",
        "\n",
        "columns_in_hundreds = train_mean_values[(train_mean_values >= 100) & (train_mean_values < 1000)].count()\n",
        "print(columns_in_hundreds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrkhz-Qg0ZBb",
        "outputId": "14090f80-6da9-4183-81e8-ad5f4122a94b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_3 = pd.read_csv('Data_train.csv')\n",
        "df_test_3 = pd.read_csv('Data_test.csv')\n",
        "print(df_train_3.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSsFSo5e1tn7",
        "outputId": "3c3b9e82-2283-4a5a-80a7-c46ec3a495a0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       type    group          education      meal preparation course  score-1  \\\n",
            "0      wild  group B   some high school  standard          completed       63   \n",
            "1  domestic  group C  bachelor's degree  standard               none       67   \n",
            "2  domestic  group C       some college  standard          completed       69   \n",
            "3  domestic  group B   some high school  standard               none       62   \n",
            "4      wild  group E       some college   reduced               none       93   \n",
            "\n",
            "   score-2  score-3  \n",
            "0       67       67  \n",
            "1       69       75  \n",
            "2       90       88  \n",
            "3       64       66  \n",
            "4       90       83  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_test_3.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv29E-Dm3ayy",
        "outputId": "e47e1f5e-8781-4904-ddb3-95fff8726c08"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       type    group           education      meal preparation course\n",
            "0      wild  group D        some college  standard               none\n",
            "1      wild  group C     master's degree   reduced          completed\n",
            "2      wild  group B        some college   reduced          completed\n",
            "3      wild  group A  associate's degree   reduced               none\n",
            "4  domestic  group B        some college  standard          completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train_3.shape)\n",
        "print(df_train_3.describe())\n",
        "print(df_train_3.describe(exclude=['number']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlViqW_p7JBb",
        "outputId": "4093b139-a1af-4e23-babd-f7776ce3184f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(700, 8)\n",
            "          score-1     score-2     score-3\n",
            "count  700.000000  700.000000  700.000000\n",
            "mean    66.028571   69.038571   67.828571\n",
            "std     15.140138   14.589664   15.152323\n",
            "min      0.000000   17.000000   10.000000\n",
            "25%     56.000000   59.000000   57.000000\n",
            "50%     66.000000   70.000000   68.000000\n",
            "75%     77.000000   79.000000   78.000000\n",
            "max    100.000000  100.000000  100.000000\n",
            "            type    group           education      meal preparation course\n",
            "count        700      680                 700       700                700\n",
            "unique         2        5                   6         2                  2\n",
            "top     domestic  group C  associate's degree  standard               none\n",
            "freq         357      207                 154       444                442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_test_3.shape)\n",
        "print(df_test_3.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ok-HBmbKVRu",
        "outputId": "5c051887-817b-4041-b7e7-af8475abc58e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300, 5)\n",
            "            type    group     education      meal preparation course\n",
            "count        300      288           300       300                300\n",
            "unique         2        5             6         2                  2\n",
            "top     domestic  group C  some college  standard               none\n",
            "freq         161      103            76       201                200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 1 (0.25 балла). Заполните пропуски в столбце уникальной категорией, если столбец с пропуском категориальный, и средним значением, если столбец числовой. Заполняйте одновременно и df_train, и df_test - одинаковым образом. В ответе укажите количество различных значений, потребовавшихся для заполнения пропусков (это равно количеству новых уникальных категорий плюс количество средних значений для заполнения пропусков в числовых столбцах).\n",
        "\n"
      ],
      "metadata": {
        "id": "u2wit7tJOPTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_missing_3 = df_train_3.isnull().sum() # get missing in train\n",
        "test_missing = df_test_3.isnull().sum() # get missing in test\n",
        "num_train_columns_with_missing = (train_missing_3 > 0).sum()\n",
        "num_test_columns_with_missing = (test_missing > 0).sum()\n",
        "print(num_train_columns_with_missing)\n",
        "print(num_test_columns_with_missing)\n",
        "\n",
        "numeric_columns_train = df_train_3.select_dtypes(include=['number']).columns\n",
        "numeric_columns_test = df_test_3.select_dtypes(include=['number']).columns\n",
        "categorical_columns_train = df_train_3.select_dtypes(exclude=['number']).columns\n",
        "categorical_columns_test = df_test_3.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "mean_values_train = df_train_3[numeric_columns_train].mean()\n",
        "mean_values_test = df_test_3[numeric_columns_test].mean()\n",
        "df_train_3[numeric_columns_train] = df_train_3[numeric_columns_train].fillna(mean_values_train)\n",
        "df_test_3[numeric_columns_test] = df_test_3[numeric_columns_test].fillna(mean_values_test)\n",
        "\n",
        "unique_category = 'unknown'\n",
        "\n",
        "df_train_3[categorical_columns_train] = df_train_3[categorical_columns_train].fillna(unique_category)\n",
        "df_test_3[categorical_columns_test] = df_test_3[categorical_columns_test].fillna(unique_category)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VspU1Dos16lf",
        "outputId": "34b724cb-c320-4430-8d3b-fa143788c7aa"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 2 (0.3 балла)\n",
        "Если у телефона нет ни опции 3G, ни опции 4G, ни Wifi - то у пользователей нет доступа к интернету. Создайте колонку is_internet и поставьте туда 0, если у телефона нет ни одной из трех перечисленных опций, и 1 иначе.\n",
        "\n",
        "Такую же колонку создайте в тестовых данных.\n",
        "\n",
        "Какая доля телефонов (из train.csv) не имеет доступа к интернету? Ответ округлите до сотых."
      ],
      "metadata": {
        "id": "C0fDhkIEORIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_2['is_internet'] = df_train_2.apply(lambda row: 1 if row['three_g'] == 1 or row['four_g'] == 1 or row['wifi'] == 1 else 0, axis=1)\n",
        "df_test_2['is_internet'] = df_test_2.apply(lambda row: 1 if row['three_g'] == 1 or row['four_g'] == 1 or row['wifi'] == 1 else 0, axis=1)\n",
        "\n",
        "# Вычисление доли телефонов без доступа к интернету\n",
        "no_internet_share = (df_train_2['is_internet'] == 0).mean()\n",
        "\n",
        "# Округление до сотых\n",
        "no_internet_share_rounded = round(no_internet_share, 2)\n",
        "\n",
        "# Вывод результата\n",
        "print(\"Доля телефонов без доступа к интернету:\", no_internet_share_rounded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGqB06DTMCC4",
        "outputId": "4198b7a3-e8a1-4653-8729-be9366041d04"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Доля телефонов без доступа к интернету: 0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) (0.05 балла). В столбце с наибольшим количеством пропусков заполните пропуски средним значением по столбцу. В ответ запишите значение вычисленного среднего.  Ответ округлите до десятых.\n"
      ],
      "metadata": {
        "id": "Yu7euAAlOaMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column_with_most_missing = train_missing.idxmax()\n",
        "mean_value = df_train_1[column_with_most_missing].mean()\n",
        "df_train_1[column_with_most_missing].fillna(mean_value, inplace=True)\n",
        "updated_mean_value = df_train_1[column_with_most_missing].mean()\n",
        "\n",
        "# Округление до десятых\n",
        "updated_mean_value_rounded = round(updated_mean_value, 1)\n",
        "\n",
        "# Вывод результата\n",
        "print(f\"Столбец с наибольшим количеством пропусков: {column_with_most_missing}\")\n",
        "print(f\"Заполненное среднее значение: {updated_mean_value_rounded}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkX56D0KNGhq",
        "outputId": "cc2adacc-121f-4f0f-e49b-afc56c9c48cf"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Столбец с наибольшим количеством пропусков: 1\n",
            "Заполненное среднее значение: 31.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) (0.1 балла). Найдите строки в тренировочных данных, где пропуски стоят в столбце с наименьшим количеством пропусков. Удалите эти строки. Сколько строк вы удалили?\n",
        "\n"
      ],
      "metadata": {
        "id": "tgQeVGE1OfGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подсчет пропусков в каждой строке\n",
        "missing_counts_per_row = df_train_1.isnull().sum(axis=1)\n",
        "# Находим столбец с наименьшим количеством пропусков\n",
        "column_with_least_missing = missing_counts_per_row.idxmin()\n",
        "# Выбираем строки с пропусками в этом столбце\n",
        "rows_to_drop = df_train_1[missing_counts_per_row > 0]\n",
        "# Удаляем выбранные строки\n",
        "df_train_cleaned = df_train_1.drop(rows_to_drop.index)\n",
        "# Подсчитываем количество удаленных строк\n",
        "num_rows_dropped = len(rows_to_drop)\n",
        "print(num_rows_dropped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE3V6XmxNhtF",
        "outputId": "8a09d0f6-59b2-44a3-abf0-9a0068d24132"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train_1.describe(exclude=['number']))\n",
        "unique_values = df_train_1.apply(lambda x: x.unique())\n",
        "print(unique_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4ZoNw9LQORf",
        "outputId": "ba9e2b99-4606-475f-d3fb-09deb502791e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          7     target\n",
            "count   513        513\n",
            "unique    2          4\n",
            "top       A  Not churn\n",
            "freq    279        278\n",
            "0                                                    [1, 0]\n",
            "1         [34.75, 19.17, 20.25, 31.28322514908239, 22.58...\n",
            "2         [15.0, 4.0, 9.96, 28.0, 1.5, 1.0, 3.165, 7.585...\n",
            "3                                                 [2, 1, 3]\n",
            "4           [12, 3, 10, 8, 6, 11, 14, 9, 13, 1, 4, 7, 2, 5]\n",
            "5                                  [7, 4, 2, 5, 8, 1, 9, 3]\n",
            "6         [5.375, 1.0, 0.0, 28.5, 0.54, 5.0, 3.165, 7.58...\n",
            "7                                                    [A, B]\n",
            "8                                                    [1, 0]\n",
            "9         [9, 0, 40, 2, 3, 15, 1, 7, 4, 5, 6, 11, 14, 20...\n",
            "10                                                   [1, 0]\n",
            "11                                                [2, 1, 3]\n",
            "12        [0, 360, 120, 167, 290, 380, 60, 340, 220, 100...\n",
            "13        [135.0, 1001.0, 1.0, 16.0, 68.0, 501.0, 2280.0...\n",
            "target                 [Churn, Not churn, Chorn, Not chorn]\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Переведите столбец с целевой переменной в бинарные значения по правилу: Churn - 1, Not churn - 0. Исправьте опечатки в названиях категорий целевой переменной (до того, как переводить их в бинарные значения).\n",
        "\n",
        "Сколько опечаток вы исправили?"
      ],
      "metadata": {
        "id": "x4amXiWQQ5-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "need_to_fix = df_train_1['target'].isin(['Chorn', 'Not chorn']).sum()\n",
        "print(need_to_fix)\n",
        "\n",
        "df_train_1['target'] = df_train_1['target'].replace({'Chorn': 'Churn', 'Not chorn': 'Not churn'})\n",
        "\n",
        "# Преобразуем значения в бинарные\n",
        "df_train_1['target'] = df_train_1['target'].map({'Churn': 1, 'Not churn': 0})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-4-JbR6Q5tu",
        "outputId": "f2d81c2b-fee1-4315-80e7-a3d5e6bda910"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Верно ли, что если значение единственного категориального признака в таблице равно A, то клиент уйдет из компании? (target = 1) В ответ запишите “да” или “нет” без кавычек."
      ],
      "metadata": {
        "id": "lj8T16qnSkEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Фильтруем DataFrame по условиям\n",
        "filtered_rows = df_train_1[(df_train_1['7'] == 'A') & (df_train_1['target'] == 0)]\n",
        "\n",
        "# Подсчитываем количество строк в результате фильтрации\n",
        "num_rows = len(filtered_rows)\n",
        "print(num_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As6ArTTeSTte",
        "outputId": "7c4ac9c5-b61f-49fb-943b-2af63ebe8c68"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вычислите долю ушедших из компании клиентов, для которых значение признака 2 больше среднего значения по столбцу, а значение признака 13 меньше медианы по столбцу. Ответ округлите до сотых."
      ],
      "metadata": {
        "id": "TBPSlfXsSmel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_feature_2 = df_train_1['2'].mean()\n",
        "median_feature_13 = df_train_1['13'].median()\n",
        "\n",
        "# Определяем строки, удовлетворяющие условиям\n",
        "filtered_rows = df_train_1[(df_train_1['2'] > mean_feature_2) & (df_train_1['13'] < median_feature_13)]\n",
        "rows2 = filtered_rows[filtered_rows['target'] == 1]\n",
        "\n",
        "# Вычисляем долю ушедших клиентов относительно общего числа строк\n",
        "churn_ratio = len(rows2) / len(filtered_rows)\n",
        "\n",
        "# Ответ округляем до сотых\n",
        "churn_ratio_rounded = round(churn_ratio, 2)\n",
        "\n",
        "# Выводим результат\n",
        "print(\"Доля ушедших клиентов:\", churn_ratio_rounded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvidI3E1SnS9",
        "outputId": "ee884968-6559-44e5-9a89-b5bbceb7a3f6"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Доля ушедших клиентов: 0.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) (0.25 балла) Закодируйте категориальные столбцы в тренировочных и тестовых данных при помощи label encoding (категории кодируйте подряд идущими числами, начинающимися с 0).\n",
        "\n",
        "\n",
        "Сколько столбцов после кодировки стало в тестовых данных?"
      ],
      "metadata": {
        "id": "m-dh97FDWIWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Загрузка данных\n",
        "df_train = pd.read_csv('TrainData.csv')\n",
        "df_test = pd.read_csv('TestData.csv')\n",
        "\n",
        "# заполнить пропущенные записи и все предыдущие пункты\n",
        "\n",
        "# Создание объекта LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Функция для кодировки категориальных столбцов\n",
        "def encode_categorical(df):\n",
        "    for column in df.select_dtypes(include=['object']).columns:\n",
        "        df[column] = label_encoder.fit_transform(df[column])\n",
        "    return df\n",
        "\n",
        "# Применение LabelEncoder к тренировочным и тестовым данным\n",
        "df_train = encode_categorical(df_train)\n",
        "df_test = encode_categorical(df_test)\n",
        "\n",
        "# Определение количества столбцов в тестовых данных после кодировки\n",
        "num_columns_test_encoded = df_test.shape[1]\n",
        "\n",
        "# Вывод количества столбцов\n",
        "print(\"Количество столбцов после кодировки в тестовых данных:\", num_columns_test_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyQdoKAYWHms",
        "outputId": "e37ac151-696f-4478-b3e0-b704bffbb89f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество столбцов после кодировки в тестовых данных: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) (0.5 балла) Разбейте тренировочные данные на целевой вектор y, содержащий значения из столбца target, и матрицу объект-признак X, содержащую остальные признаки. Обучите на этих данных логистическую регрессию из sklearn (LogisticRegression) с параметрами по умолчанию. Выведите среднее значение метрики f1-score алгоритма на кросс-валидации с тремя фолдами. Ответ округлите до сотых.\n",
        "\n",
        "При объявлении модели фиксируйте random_state = 42.\n",
        "\n",
        "Комментарий: параметры по умолчанию предполагаются следующими\n",
        "\n",
        "penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None"
      ],
      "metadata": {
        "id": "WtH__58iWcnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "\n",
        "X = df_train.drop(columns=['target'])\n",
        "y = df_train['target']\n",
        "\n",
        "# Создание и обучение модели логистической регрессии\n",
        "model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Определение метрики f1-score для кросс-валидации\n",
        "f1_scorer = make_scorer(f1_score)\n",
        "\n",
        "# Кросс-валидация с тремя фолдами, добавим обработку ошибок\n",
        "try:\n",
        "    scores = cross_val_score(model, X, y, cv=3, scoring=f1_scorer)\n",
        "    # Вычисление среднего значения метрики f1-score\n",
        "    mean_f1_score = scores.mean()\n",
        "    # Округление до сотых\n",
        "    mean_f1_score_rounded = round(mean_f1_score, 2)\n",
        "    # Вывод результата\n",
        "    print(\"Среднее значение f1-score на кросс-валидации:\", mean_f1_score_rounded)\n",
        "except Exception as e:\n",
        "    print(\"Ошибка при выполнении кросс-валидации:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UWESTFDWdb-",
        "outputId": "2c0d5552-cd38-4c3d-d6d5-8546903efec6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ошибка при выполнении кросс-валидации: \n",
            "All the 3 fits failed.\n",
            "It is very likely that your model is misconfigured.\n",
            "You can try to debug the error by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1196, in fit\n",
            "    X, y = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 584, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n",
            "    X = check_array(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input X contains NaN.\n",
            "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. a) Подберите значение константы регуляризации C в логистической регрессии, перебирая гиперпараметр от 0.001 до 100 включительно, проходя по степеням 10. Для выбора С примените перебор по сетке по тренировочной выборке (GridSearchCV из библиотеки sklearn.model_selection) с тремя фолдами и метрикой качества - f1-score. Остальные параметры оставьте по умолчанию. В ответ запишите наилучшее среди искомых значение С. (0.25 балла)\n",
        "\n",
        "При объявлении модели фиксируйте random_state = 42.\n",
        "\n",
        "Комментарий: параметры по умолчанию предполагаются следующими\n",
        "\n",
        "penalty='l2', dual=False, tol=0.0001, fit_intercept=True, intercept_scaling=1, class_weight=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None\n",
        "\n",
        "b) Добавьте в тренировочные и тестовые данные новый признак ‘NEW’, равный произведению признаков ‘7’ и ‘11’.\n",
        "\n",
        "\n",
        "На тренировочных данных с новым признаком заново с помощью GridSearchCV (с тремя фолдами и метрикой качества - f1-score) подберите оптимальное значение С (перебирайте те же значения С, что и в предыдущих заданиях), в ответ напишите наилучшее качество алгоритма (по метрике f1-score), ответ округлите до сотых. (0.5 балла).\n",
        "\n",
        "При объявлении модели фиксируйте random_state = 42.\n",
        "\n",
        "Комментарий: параметры по умолчанию предполагаются следующими\n",
        "\n",
        "penalty='l2', dual=False, tol=0.0001, fit_intercept=True, intercept_scaling=1, class_weight=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None\n",
        "\n",
        "c) Теперь вы можете использовать любую модель машинного обучения для решения задачи. Также можете делать любую другую обработку признаков. Ваша задача - получить наилучшее качество по метрике accuracy на тестовых данных. (0.75 балла)\n",
        "\n",
        "\n",
        "Качество проверяется на представленных тестовых данных.\n",
        "\n",
        "accuracy >= 0.88 - 0.25 балла\n",
        "accuracy >= 0.9 - 0.75 балла\n",
        "Сдайте файл result.csv. Во вложении пример файла для отправки результатов: result.csv\n",
        "Задание считается выполненным, если загруженный файл прошел предпроверку и получил необходимые баллы. Не обращайте внимание на статус \"Не завершено\" слева от задания.\n",
        "Внимание! Учитывается результат последней посылки! Перед завершением теста убедитесь, что вы отправили последним самое точное предсказание."
      ],
      "metadata": {
        "id": "wGL79GThYt0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Загрузка данных\n",
        "df_train = pd.read_csv('TrainData.csv')\n",
        "df_test = pd.read_csv('TestData.csv')\n",
        "\n",
        "# Кодирование категориальных столбцов\n",
        "label_encoder = LabelEncoder()\n",
        "for column in df_train.select_dtypes(include=['object']).columns:\n",
        "    df_train[column] = label_encoder.fit_transform(df_train[column])\n",
        "    df_test[column] = label_encoder.fit_transform(df_test[column])\n",
        "\n",
        "# Разделение данных на целевой вектор y и матрицу объект-признак X\n",
        "X_train = df_train.drop(columns=['target'])\n",
        "y_train = df_train['target']\n",
        "\n",
        "# Определение параметров для GridSearchCV\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Создание и обучение GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='f1')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Вывод наилучшего значения C\n",
        "best_C = grid_search.best_params_['C']\n",
        "print(\"Наилучшее значение C:\", best_C)"
      ],
      "metadata": {
        "id": "juKBvO_5YSMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавление нового признака 'NEW'\n",
        "df_train['NEW'] = df_train['7'] * df_train['11']\n",
        "df_test['NEW'] = df_test['7'] * df_test['11']\n",
        "\n",
        "# Разделение данных на целевой вектор y и матрицу объект-признак X\n",
        "X_train_new = df_train.drop(columns=['target'])\n",
        "y_train_new = df_train['target']\n",
        "\n",
        "# Создание и обучение GridSearchCV\n",
        "grid_search_new = GridSearchCV(model, param_grid, cv=3, scoring='f1')\n",
        "grid_search_new.fit(X_train_new, y_train_new)\n",
        "\n",
        "# Вывод наилучшего значения C\n",
        "best_C_new = grid_search_new.best_params_['C']\n",
        "best_f1_score = grid_search_new.best_score_\n",
        "print(\"Наилучшее значение C с новым признаком:\", best_C_new)\n",
        "print(\"Наилучшее значение f1-score с новым признаком:\", round(best_f1_score, 2))"
      ],
      "metadata": {
        "id": "fwBng8iNYx5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# Создание и обучение RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train_new, y_train_new)\n",
        "\n",
        "# Предсказание и оценка на тестовых данных\n",
        "X_test_new = df_test.drop(columns=['target'])\n",
        "y_test = df_test['target']\n",
        "\n",
        "y_pred_rf = rf_model.predict(X_test_new)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Точность RandomForestClassifier:\", round(rf_accuracy, 2))\n",
        "\n",
        "# Создание и обучение XGBoost\n",
        "xgb_model = xgb.XGBClassifier(random_state=42)\n",
        "xgb_model.fit(X_train_new, y_train_new)\n",
        "\n",
        "# Предсказание и оценка на тестовых данных\n",
        "y_pred_xgb = xgb_model.predict(X_test_new)\n",
        "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
        "print(\"Точность XGBoost:\", round(xgb_accuracy, 2))\n",
        "\n",
        "# Сохранение лучшей модели\n",
        "best_model = rf_model if rf_accuracy > xgb_accuracy else xgb_model\n",
        "best_accuracy = max(rf_accuracy, xgb_accuracy)\n",
        "print(\"Наилучшая точность модели:\", round(best_accuracy, 2))"
      ],
      "metadata": {
        "id": "eiEANt4UY0gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание файла с результатами\n",
        "result_df = pd.DataFrame({'id': df_test.index, 'target': best_model.predict(X_test_new)})\n",
        "result_df.to_csv('result.csv', index=False)"
      ],
      "metadata": {
        "id": "Z62Om80-Y7ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разбейте тренировочные данные на целевой вектор y, содержащий значения из столбца price_range, и матрицу объект-признак X, содержащую остальные признаки.\n",
        "\n",
        "Посмотрите, сколько значений содержит категориальный столбец touch_screen. Значения, встречающиеся меньше, чем в 1% строк, замените на самое частое значение. После этого закодируйте столбец при помощи OneHot-encoding (используйте аргумент drop='first'). Обучайте OHE на тренировочных данных X, но кодируйте при этом и тренировочные, и тестовые данные.  Для кросс-валидации лучше использовать функцию cross_val_score из библиотеки sklearn.model_selection.\n",
        "\n",
        "Сколько изначально различных значений было в столбце touch_screen?\n",
        "\n",
        "b (0.4 балла) Обучите на этих данных логистическую регрессию из sklearn (LogisticRegression) с параметрами по умолчанию. Выведите среднее значение метрики f1_score c вариантом усреднения ‘weighted’  (или же 'f1_weighted') алгоритма на кросс-валидации с тремя фолдами. Ответ округлите до сотых.\n",
        "\n",
        "При объявлении модели задайте random_state = 42.\n",
        "\n",
        "Комментарий: параметры по умолчанию предполагаются следующими:\n",
        "\n",
        "penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None\n",
        "\n",
        "a. Подберите значение константы регуляризации C в логистической регрессии, перебирая гиперпараметр от 0.001 до 100 включительно, проходя по степеням 10. Для выбора С примените перебор по сетке по тренировочной выборке (GridSearchCV из библиотеки sklearn.model_selection) с тремя фолдами и метрикой качества - f1_weighted. Остальные параметры оставьте по умолчанию. В ответ запишите наилучшее среди искомых значение С. (0.25 балла)\n",
        "\n",
        "При объявлении модели задайте random_state = 42.\n",
        "\n",
        "Комментарий: параметры по умолчанию предполагаются следующими:\n",
        "\n",
        "penalty='l2', dual=False, tol=0.0001, fit_intercept=True, intercept_scaling=1, class_weight=None,  solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None\n",
        "\n",
        "b. Добавьте в тренировочные и тестовые данные новый признак ‘ram_resolution’, вычисляемый по формуле ram * (px_height + px_width)\n",
        "\n",
        "На тренировочных данных с новым признаком заново с помощью GridSearchCV (с тремя фолдами и метрикой качества - f1_weighted) подберите оптимальное значение С (перебирайте те же значения С, что и в предыдущих заданиях), в ответ напишите наилучшее качество алгоритма по метрике f1_weighted (можно посмотреть, обратившись к полю best_score_ обученного GridSearchCV), ответ округлите до сотых. (0.5 балла).\n",
        "\n",
        "Комментарий: параметры по умолчанию предполагаются следующими\n",
        "\n",
        "penalty='l2', dual=False, tol=0.0001, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None\n",
        "\n",
        "с. Теперь вы можете использовать любую модель машинного обучения для решения задачи. Также можете делать любую другую обработку признаков. Ваша задача - получить наилучшее качество по метрике f1_weighted на тестовых данных. (0.75 балла)\n",
        "\n",
        "Качество проверяется на представленных тестовых данных.\n",
        "\n",
        "* f1_weighted >= 0.88 - 0.25 балла\n",
        "\n",
        "* f1_weighted >= 0.93 - 0.75 балла"
      ],
      "metadata": {
        "id": "m7QvCqAfZdw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Загрузка данных\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Разделение данных на X и y\n",
        "X_train = train_data.drop(columns=['price_range'])\n",
        "y_train = train_data['price_range']"
      ],
      "metadata": {
        "id": "YuljpVlzZAEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подсчет уникальных значений\n",
        "touch_screen_counts = X_train['touch_screen'].value_counts()\n",
        "initial_unique_values = len(touch_screen_counts)\n",
        "\n",
        "# Замена значений, встречающихся менее 1% строк, на самое частое значение\n",
        "threshold = 0.01 * len(X_train)\n",
        "most_frequent_value = touch_screen_counts.idxmax()\n",
        "X_train['touch_screen'] = X_train['touch_screen'].apply(lambda x: most_frequent_value if touch_screen_counts[x] < threshold else x)\n",
        "\n",
        "# OneHot-Encoding\n",
        "encoder = OneHotEncoder(drop='first', sparse=False)\n",
        "touch_screen_encoded = encoder.fit_transform(X_train[['touch_screen']])\n",
        "touch_screen_encoded_df = pd.DataFrame(touch_screen_encoded, columns=encoder.get_feature_names_out(['touch_screen']))\n",
        "\n",
        "# Замена столбца touch_screen на закодированный вариант\n",
        "X_train = X_train.drop(columns=['touch_screen'])\n",
        "X_train = pd.concat([X_train, touch_screen_encoded_df], axis=1)\n",
        "\n",
        "# Применение того же кодирования к тестовым данным\n",
        "X_test = test_data.drop(columns=['price_range'])\n",
        "X_test['touch_screen'] = X_test['touch_screen'].apply(lambda x: most_frequent_value if touch_screen_counts.get(x, 0) < threshold else x)\n",
        "touch_screen_encoded_test = encoder.transform(X_test[['touch_screen']])\n",
        "touch_screen_encoded_test_df = pd.DataFrame(touch_screen_encoded_test, columns=encoder.get_feature_names_out(['touch_screen']))\n",
        "X_test = X_test.drop(columns=['touch_screen'])\n",
        "X_test = pd.concat([X_test, touch_screen_encoded_test_df], axis=1)\n",
        "\n",
        "print(\"Изначально различных значений в столбце touch_screen:\", initial_unique_values)"
      ],
      "metadata": {
        "id": "RJhZ-JeqZhLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели логистической регрессии\n",
        "model = LogisticRegression(random_state=42)\n",
        "f1_scores = cross_val_score(model, X_train, y_train, cv=3, scoring='f1_weighted')\n",
        "mean_f1_score = f1_scores.mean()\n",
        "print(\"Среднее значение f1_score:\", round(mean_f1_score, 2))"
      ],
      "metadata": {
        "id": "pRj7ZFbSZmr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Определение параметров для GridSearchCV\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Создание и обучение GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='f1_weighted')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Вывод наилучшего значения C\n",
        "best_C = grid_search.best_params_['C']\n",
        "print(\"Наилучшее значение C:\", best_C)"
      ],
      "metadata": {
        "id": "v-8gVXfvZpRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавление нового признака 'ram_resolution'\n",
        "X_train['ram_resolution'] = X_train['ram'] * (X_train['px_height'] + X_train['px_width'])\n",
        "X_test['ram_resolution'] = X_test['ram'] * (X_test['px_height'] + X_test['px_width'])\n",
        "\n",
        "# Создание и обучение GridSearchCV\n",
        "grid_search_new = GridSearchCV(model, param_grid, cv=3, scoring='f1_weighted')\n",
        "grid_search_new.fit(X_train, y_train)\n",
        "\n",
        "# Вывод наилучшего значения C и f1_score\n",
        "best_C_new = grid_search_new.best_params_['C']\n",
        "best_f1_score = grid_search_new.best_score_\n",
        "print(\"Наилучшее значение C с новым признаком:\", best_C_new)\n",
        "print(\"Наилучшее значение f1_score с новым признаком:\", round(best_f1_score, 2))"
      ],
      "metadata": {
        "id": "GYrBU4EMZr-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# Создание и обучение RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Предсказание и оценка на тестовых данных\n",
        "y_test = test_data['price_range']\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "rf_f1_weighted = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "print(\"f1_weighted RandomForestClassifier:\", round(rf_f1_weighted, 2))\n",
        "\n",
        "# Создание и обучение XGBoost\n",
        "xgb_model = xgb.XGBClassifier(random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Предсказание и оценка на тестовых данных\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "xgb_f1_weighted = f1_score(y_test, y_pred_xgb, average='weighted')\n",
        "print(\"f1_weighted XGBoost:\", round(xgb_f1_weighted, 2))\n",
        "\n",
        "# Сохранение лучшей модели\n",
        "best_model = rf_model if rf_f1_weighted > xgb_f1_weighted else xgb_model\n",
        "best_f1_weighted = max(rf_f1_weighted, xgb_f1_weighted)\n",
        "print(\"Наилучшая f1_weighted модели:\", round(best_f1_weighted, 2))"
      ],
      "metadata": {
        "id": "02G5XmhoZxCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) (0.3 баллa). Далее используйте только категориальные столбцы. Закодируйте их с помощью One-hot encoding с учетом того, что мы не хотим получить мультиколлинеарности в новых данных. Сколько получилось числовых столбцов из исходных категориальных? Кодируйте и df_train, и df_test.\n",
        "\n",
        "б) (0.4 балла). Попытаемся по характеристикам кошки (бывшие категориальные, а теперь - числовые столбцы) предсказать, прошла она полосу препятствий или нет.\n",
        "\n",
        "\n",
        "Сформируйте из df_train матрицу объект-признак X и вектор ответов y.\n",
        "\n",
        "\n",
        "Обучите решающее дерево (DecisionTreeClassifier из библиотеки sklearn.tree) глубины 5 с энтропийным критерием информативности на закодированных в пункте а) тренировочных данных по кросс-валидации с тремя фолдами, метрика качества - roc-auc.\n",
        "\n",
        "\n",
        "Чему равен roc-auc, усредненный по фолдам? Ответ округлите до десятых.\n",
        "\n",
        "\n",
        "Комментарий: остальные гиперпараметры дерева оставьте дефолтными (splitter='best', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, ccp_alpha=0.0)\n",
        "\n",
        "Задание 6 (1.5 балла максимум).\n",
        "\n",
        "\n",
        "a) (0.25 балла). Подберите глубину решающего дерева (max_depth), перебирая глубину от 2 до 20 с шагом 1 и используя перебор по сетке (GridSearchCV из библиотеки sklearn.model_selection) с тремя фолдами и метрикой качества - roc-auc. В ответ запишите наилучшее среди искомых значение max_depth.\n",
        "\n",
        "\n",
        "Комментарий: остальные гиперпараметры дерева оставьте дефолтными (splitter='best', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, ccp_alpha=0.0)\n",
        "\n",
        "б) (0.5 балла). Добавьте к данным новый признак cat_bio, содержащий в качестве значений пары значений из столбца type и столбца group. Например, если кошка имеет type='wild' и  group='group B', то в cat_bio будет стоять строка '(wild, group B)'. Примените OneHotEncoding (с учетом того, что мы не хотим получить мультиколлинеарности в новых данных) к столбцам 'cat_bio', 'education', 'meal', 'preparation course', а затем обучите решающее дерево глубины 5 с энтропийным критерием информативности на полученных после кодирования данных. Чему равен roc-auc? Ответ округлите до сотых.\n",
        "\n",
        "Комментарий: остальные гиперпараметры дерева оставьте дефолтными (splitter='best', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, ccp_alpha=0.0)\n",
        "\n",
        "в) (0.75 балла). Теперь вы можете использовать любую модель машинного обучения для решения задачи. Также можете делать любую другую обработку признаков. Ваша задача - получить наилучшее качество (ROC_AUC).\n",
        "\n",
        "Качество проверяется на тестовых данных.\n",
        "\n",
        "ROC_AUC > 0.7 - 0.25 балла\n",
        "ROC_AUC > 0.74 - 0.75 балла"
      ],
      "metadata": {
        "id": "RxAHmrrjaJdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Загрузка данных\n",
        "df_train = pd.read_csv('TrainData.csv')\n",
        "df_test = pd.read_csv('TestData.csv')\n",
        "\n",
        "# Определение категориальных столбцов\n",
        "categorical_columns = df_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "# One-Hot Encoding с параметром drop='first'\n",
        "encoder = OneHotEncoder(drop='first', sparse=False)\n",
        "encoded_train = encoder.fit_transform(df_train[categorical_columns])\n",
        "encoded_test = encoder.transform(df_test[categorical_columns])\n",
        "\n",
        "# Преобразование закодированных данных обратно в DataFrame\n",
        "encoded_train_df = pd.DataFrame(encoded_train, columns=encoder.get_feature_names_out(categorical_columns))\n",
        "encoded_test_df = pd.DataFrame(encoded_test, columns=encoder.get_feature_names_out(categorical_columns))\n",
        "\n",
        "# Объединение закодированных данных с оригинальными DataFrame, исключая исходные категориальные столбцы\n",
        "df_train_encoded = pd.concat([df_train.drop(columns=categorical_columns), encoded_train_df], axis=1)\n",
        "df_test_encoded = pd.concat([df_test.drop(columns=categorical_columns), encoded_test_df], axis=1)\n",
        "\n",
        "# Количество новых столбцов, полученных в результате кодирования\n",
        "num_new_columns = len(encoded_train_df.columns)\n",
        "\n",
        "print(f\"Количество новых столбцов из исходных категориальных: {num_new_columns}\")"
      ],
      "metadata": {
        "id": "EaMkJ3uQaNRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score, make_scorer\n",
        "\n",
        "# Формирование матрицы объект-признак X и вектора ответов y\n",
        "X = df_train_encoded.drop(columns=['target'])\n",
        "y = df_train_encoded['target']\n",
        "\n",
        "# Инициализация модели решающего дерева\n",
        "tree = DecisionTreeClassifier(max_depth=5, criterion='entropy', random_state=42)\n",
        "\n",
        "# Оценка модели с использованием кросс-валидации\n",
        "roc_auc_scorer = make_scorer(roc_auc_score)\n",
        "scores = cross_val_score(tree, X, y, cv=3, scoring=roc_auc_scorer)\n",
        "\n",
        "# Усредненное значение ROC-AUC\n",
        "average_roc_auc = scores.mean()\n",
        "print(f\"Усредненное значение ROC-AUC по фолдам: {average_roc_auc:.1f}\")"
      ],
      "metadata": {
        "id": "8pOMaqwmaQbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Настройка сетки гиперпараметров\n",
        "param_grid = {'max_depth': range(2, 21)}\n",
        "\n",
        "# Инициализация модели решающего дерева\n",
        "tree = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "\n",
        "# Инициализация GridSearchCV\n",
        "grid_search = GridSearchCV(tree, param_grid, cv=3, scoring=roc_auc_scorer)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Лучшее значение max_depth\n",
        "best_max_depth = grid_search.best_params_['max_depth']\n",
        "print(f\"Наилучшее значение max_depth: {best_max_depth}\")\n"
      ],
      "metadata": {
        "id": "KJjjz5Z_aTQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавление нового признака cat_bio\n",
        "df_train['cat_bio'] = list(zip(df_train['type'], df_train['group']))\n",
        "df_test['cat_bio'] = list(zip(df_test['type'], df_test['group']))\n",
        "\n",
        "# Применение OneHotEncoding к новым признакам и другим категориальным столбцам\n",
        "new_categorical_columns = ['cat_bio', 'education', 'meal', 'preparation course']\n",
        "encoder = OneHotEncoder(drop='first', sparse=False)\n",
        "encoded_train_new = encoder.fit_transform(df_train[new_categorical_columns])\n",
        "encoded_test_new = encoder.transform(df_test[new_categorical_columns])\n",
        "\n",
        "# Преобразование закодированных данных обратно в DataFrame\n",
        "encoded_train_new_df = pd.DataFrame(encoded_train_new, columns=encoder.get_feature_names_out(new_categorical_columns))\n",
        "encoded_test_new_df = pd.DataFrame(encoded_test_new, columns=encoder.get_feature_names_out(new_categorical_columns))\n",
        "\n",
        "# Объединение закодированных данных с оригинальными DataFrame\n",
        "df_train_new_encoded = pd.concat([df_train.drop(columns=new_categorical_columns), encoded_train_new_df], axis=1)\n",
        "df_test_new_encoded = pd.concat([df_test.drop(columns=new_categorical_columns), encoded_test_new_df], axis=1)\n",
        "\n",
        "# Формирование матрицы объект-признак X_new и вектора ответов y\n",
        "X_new = df_train_new_encoded.drop(columns=['target'])\n",
        "y = df_train_new_encoded['target']\n",
        "\n",
        "# Обучение модели и оценка качества\n",
        "tree_new = DecisionTreeClassifier(max_depth=5, criterion='entropy', random_state=42)\n",
        "scores_new = cross_val_score(tree_new, X_new, y, cv=3, scoring=roc_auc_scorer)\n",
        "average_roc_auc_new = scores_new.mean()\n",
        "print(f\"Усредненное значение ROC-AUC по фолдам с новым признаком: {average_roc_auc_new:.2f}\")\n"
      ],
      "metadata": {
        "id": "uhRxEhSeacjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Использование случайного леса\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_new, y)\n",
        "\n",
        "# Предсказания на тестовых данных\n",
        "X_test_new = df_test_new_encoded.drop(columns=['target'])\n",
        "y_test = df_test_new_encoded['target']\n",
        "y_pred = model.predict_proba(X_test_new)[:, 1]\n",
        "\n",
        "# Оценка качества на тестовых данных\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(f\"ROC_AUC на тестовых данных: {roc_auc:.2f}\")\n"
      ],
      "metadata": {
        "id": "yFY7VKuqagEl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}